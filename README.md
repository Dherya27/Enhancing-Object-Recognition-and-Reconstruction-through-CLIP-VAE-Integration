# Enhancing-Object-Recognition-and-Reconstruction-through-CLIP-VAE-Integration
 Exploring Semantic Image Generation with Noise Effects
 
![Computer Vision](https://img.shields.io/badge/Computer%20Vision-blue)
![Generative AI](https://img.shields.io/badge/Generative%20AI-green)
![CLIP](https://img.shields.io/badge/CLIP-Contrastive%20Language%20Image%20Pretraining-orange)
![vae](https://img.shields.io/badge/VAE-Variational%20Auto%20Encoder-white)
![Image Reconstruction](https://img.shields.io/badge/Image%20Reconstruction-purple)
![Robotics Application](https://img.shields.io/badge/Robotics%20Application-black)
![Cosine Similarity](https://img.shields.io/badge/Cosine%20Similarity-grey)
![Noise Injection](https://img.shields.io/badge/Noise%20Injection-yellow)

Project Overview

This project explores the integration of CLIP (Contrastive Languageâ€“Image Pretraining) with a Variational Autoencoder (VAE) for the dual tasks of object recognition and image reconstruction. By incorporating text queries and noise effects in the latent space, we aim to enhance the robustness and accuracy of object recognition and reconstruction.

## Table of Contents
1. [Introduction](#introduction)
2. [Architecture](#architecture)
3. [Installation](#installation)
4. [Usage](#usage)
5. [Results](#results)
6. [Limitation](#introduction)
7. [Future Work](#introduction)
  
# Introduction

In this project, we integrate CLIP, a powerful model for connecting text and images, with a VAE to generate and reconstruct images based on textual prompts. This approach leverages the semantic understanding of CLIP and the generative capabilities of VAE to explore new frontiers in computer vision and generative AI.

<img src="https://github.com/Dherya27/Object-Recognition-and-Reconstruction-through-CLIP-VAE-Integration/blob/main/results/reconstruction.gif">

